### Fix Python Warning (/opt/spark2/bin/pyspark2: line 45: python: command not found)
#2.x
cd /opt/spark2/bin
vi pyspark2
Edit the line 
    WORKS_WITH_IPYTHON=$(python -c 'import sys; print(sys.version_info >= (2, 7, 0))')
To
    WORKS_WITH_IPYTHON=$(python3 -c 'import sys; print(sys.version_info >= (2, 7, 0))')

### Set spark-submit Files. we can use spark-submit command to launch applications or job on a cluster.
#2.x
cp /opt/spark2/bin/spark-submit spark2-submit

#3.x
No such errors in PySpark 3.x

--Create a Spark Job
cd
vi basic.py
print("Start ...")
  
from pyspark.sql import SparkSession
spark = SparkSession \
       .builder \
       .master('yarn') \
       .appName("Python Spark SQL basic example") \
       .getOrCreate()

spark.sparkContext.setLogLevel('OFF')
print("Spark Object is created")
print("Spark Version used is :" + spark.sparkContext.version)

print("... End")

-- Submit the Job to the Cluster
spark2-submit --master yarn /home/easylearnspark1/basic.py

-- Turn off the INFO logs. Spark uses log4j for logging.
cp /opt/spark2/conf/log4j.properties.template /opt/spark2/conf/log4j.properties   
set log4j.rootCategory=INFO, console
to
log4j.rootCategory=WARN, console

spark2-submit --master yarn /home/easylearnspark1/basic.py
mv /opt/spark-2.4.8-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar /home/sibaramnanda2021/softwares  ### Resolve Class path contains multiple SLF4J bindings
spark2-submit --master yarn /home/easylearnspark1/basic.py


#3.x
cp /opt/spark3/bin/spark-submit /opt/spark3/bin/spark3-submit

-- Submit the Job to the Cluster
spark3-submit --master yarn /home/easylearnspark1/basic.py

-- Turn off the INFO logs
cp /opt/spark3/conf/log4j.properties.template /opt/spark3/conf/log4j.properties 
set log4j.rootCategory=INFO, console
to
log4j.rootCategory=WARN, console

spark3-submit --master yarn /home/easylearnspark1/basic.py


################ END ########################